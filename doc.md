# Basic evolutionary algorithm

Initialization -> loop(Selection -> Variation -> Evaluation) -> Termination

Variation = Recombination -> Mutation (on the offsprings)

# Representation

- direct representation
- indirect representation (can simplify the design of good variation operators)
  - cycle representation
  - permutation representation
  - adjacent representation
- penalty method: the search space is enlarged to D′, whose elements can be represented, and a penalty term is added to the objective function, penalizing violation of the constraints (soft or hard constraint).

The basic variation operators will be applied to the representation.

Self-adaptivity or hyperparameter search?

# Initialization

- Monte Carlo sampling

# Selection

- fitness-proportional selection
  - sigma scaling selection 
  - ranking selection
- Competition-based selection 
  - top-k selection 
  - k-tournament selection 
  - round-robin tournament selection (not recommended)

- ranking (selection pressure)
  - linear decay
  - quadratic decay
  - exponential decay

Selection pressure parameter s is often fixed, but it can also decay according to a schedule. When exponential decay ranking is chosen, the candidate solutions with the best objective value are strongly favored as s decreases. This can benefit the convergence and termination. 

# Variation
The trade-off between exploration and exploitation is partly determined by suitable variation  operators that introduce randomness and simultaneously amplify promising features of  the candidate solutions that were selected.

## Crossover/Recombination variation
Recombination of two individuals with a good objective value should lead to offspring that are close (in some distance) to the two parents. Additionally, some randomness in the generation of offspring is advised.  Recombination is typically applied with high probability (say 100%)

Recombination is more complicated and technical: See pages 65–74 in Eiben and Smith.

## Mutation variation
mutation should function like (local) random search and the probability of applying it to a candidate solution should be not too high (say 5%).

- Insert mutation
- Swap mutation
- Inversion mutation
- Scramble mutation

See slides lecture 2 for more mutation operators.

# Evaluation/Elimination

There are no fundamental differences between selection and elimination. Hence, the  foregoing selection strategies can all be used for elimination. In this case, sample without replacement.

- age-based elimination: only the new candidate solutions generated during the variation phase are retained
- the candidate solutions with the worst fitness values are eliminated
- elitism: in which the top-k individuals in the combined seed population and offspring are retained.
- (λ + μ)-elimination: The seed population and the offspring are merged (resulting in a population of size λ + μ) and then the top-λ candidate solutions are retained.
- (λ, μ)-elimination: The seed population is discarded and the top-λ candidate solutions from the offspring are retained. This requires μ > λ, typically μ/λ ≈ 5.

# Termination

# Local search

The goal of a local search operator is to locally improve one candidate solution, typically by a computationally cheap heuristic. This can guide the search process towards more interesting areas of the search space.

Initialization -> Local search -> loop(Selection -> Local search -> Variation -> Evaluation) -> Termination

In the initialization phase, the population can be enriched by 
- adding solutions generated by other heuristic methods 
- adding solutions generated by previous runs with different parameters
- applying a local search heuristic to randomly generated individuals 

Always keep a portion of the population randomly initialized to ensure sufficient diversity of the candidate solutions.

After applying recombination to generate offspring, local search
optimization can be applied to
- all offspring, 
- a random subset of the offspring, 
- the worst individuals, or 
- to the parents.

k-opt local search is a good choice for the TSP.

## Practical consideration 
Local search operators typically have tunable parameters (e.g., k in k-opt). It is recommended to make them part of the representation of a candidate solution and use self-adaptivity to learn them.

Loss of diversity: The goal of a local search operator is to push candidate
solutions towards more promising areas of the search space. This causes
more exploitation of local information. It can happen that the local search
is exploiting too much and ignoring large areas of the search space.
To combat this problem, there are several options:
- you can modify the variation operators to introduce more randomness;
- you should limit the range of allowed self-adaptable parameters;
- you could modify the elimination mechanism to explicitly promote the diversity in the population, e.g., in (λ + μ)-selection whenever an individual is selected, the most similar individual from the remaining population is eliminated.

# Promoting diversity

- Crowding
- Island model
- Fitness sharing

# Multi-objective optimization

- Fixed tradeoff or scalarization
- island model
- Pareto front approximation

# Hints 

- I reduced the population size (it s important for the big problems)
- replace inf by a big value
- I added fitness sharing for elimination
- keep k tournaments for selection
- I initialize 50% of the edges in a greedy manner meaning i choose the best edge from the remaining ones
- I added a deterministic recombination meaning i have 2 parents p1 and p2 and say i am in node x, i choose the best successor from the 2 options in the parents
- I balance that recombination with ox1 or what is the name

# Notes from Q&A2

LSO - best als een of andere random heuristic, goedkoop

Voor een goede initializatie helpt het om verzameling v technieken te gebruiken
Deels random wel best zodat geen local optima terecht komt (leidt tot clustering)
Dus aantal individuen via bepaalde heuristic, aantal op nog een andere...

Doel is echt om goede regio's te identificeren en in te zetten op exploratory deel

LSO dient niet echt om goede individuals nog beter te maken, maar eerder om richting te geven aan die dat initieel miss slecht lijken te zitten

Kan bij init
Maar moet dan deterministisch op iedereen
Zodat iedereen verbeterd anders verspilde computation voor de rest dat weggeworpen wordt

Waar toepassen? 
•⁠  ⁠Bij init, zie eerder
•⁠  ⁠Kan agressieve mutatie doen en dan toepassen op de gemuteerde om de slechte opties competitief te maken. In algoritme zelf, probabilistisch uniform toepassen dus op de gemuteerde expliciet of met kleine kans

Probleem van geclusterde fitness values -> elimination stap moet diversiteit invoeren
(Kan ook met selection deels om clustering te voorkomen)
